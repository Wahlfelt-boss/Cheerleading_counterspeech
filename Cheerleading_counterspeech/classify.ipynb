{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814a6fbc",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460bdd0a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "# Import necessary libraries if you have a specific Gemini SDK\n",
    "# e.g., from your_gemini_library import GeminiClient, ClassificationError\n",
    "\n",
    "# --- Hypothetical: Initialize client if needed (do this once outside the function if possible) ---\n",
    "# try:\n",
    "#     gemini_client = GeminiClient(api_key=\"AIzaSyA6edP593F7iybE5zMcULqp-Qe25sFfpcE\")\n",
    "# except Exception as init_e:\n",
    "#     print(f\"Failed to initialize Gemini client: {init_e}\")\n",
    "#     sys.exit(1)\n",
    "# ---------------------------------------------------------------------------------------------\n",
    "\n",
    "def classify_with_gemini(text_to_classify: str) -> int:\n",
    "    \"\"\"Classifies the text using the specified Gemini model.\n",
    "\n",
    "    Args:\n",
    "        text_to_classify: The text string to classify.\n",
    "\n",
    "    Returns:\n",
    "        Predicted label (0 for normal, 1 for counterspeech). Returns -1 if classification fails.\n",
    "    \"\"\"\n",
    "    model_name = \"gemini-2.5-pro-preview-03-25\" # As requested\n",
    "    print(f\"Classifying using {model_name}: {text_to_classify[:50]}...\")\n",
    "\n",
    "    # --- !!! REPLACE THIS HYPOTHETICAL BLOCK WITH YOUR ACTUAL API CALL !!! ---\n",
    "    try:\n",
    "        # Hypothetical function call - REPLACE with your actual call\n",
    "        response = gemini_client.classify(\n",
    "        model=model_name, \n",
    "        text=text_to_classify,\n",
    "        task_type=\"counterspeech_detection\" # Example parameter, adjust as needed\n",
    "        )\n",
    "\n",
    "        # ---- Start of Hypothetical Response Processing ----\n",
    "        # Assume 'response' is a dictionary. Adjust keys based on actual API.\n",
    "        # predicted_label_str = response.get('label', '').upper() \n",
    "\n",
    "        # ---- !!! This is a placeholder response for demonstration !!! ----\n",
    "        # ---- !!! Remove this and use the actual response from your API call !!! ----\n",
    "        import random \n",
    "        hypothetical_predictions = ['COUNTERSPEECH', 'NORMAL', 'NORMAL', 'NORMAL']\n",
    "        predicted_label_str = random.choice(hypothetical_predictions)\n",
    "        print(f\"(Hypothetical prediction: {predicted_label_str})\") \n",
    "        # ---- !!! End of Placeholder Response !!! ----\n",
    "        \n",
    "        if predicted_label_str == 'COUNTERSPEECH':\n",
    "            return 1\n",
    "        elif predicted_label_str == 'NORMAL':\n",
    "            return 0\n",
    "        else:\n",
    "            print(f\"Warning: Received unexpected label from API: {predicted_label_str}\")\n",
    "            return -1 # Indicate unexpected format\n",
    "        # ---- End of Hypothetical Response Processing ----\n",
    "\n",
    "    # except ClassificationError as api_err:\n",
    "    #     # Example: Catch specific API errors if your library provides them\n",
    "    #     print(f\"API Error classifying text '{text_to_classify[:50]}...': {api_err}\")\n",
    "    #     return -1\n",
    "    except Exception as e:\n",
    "        # Catch any general exception during the API call or processing\n",
    "        print(f\"Error during classification API call for '{text_to_classify[:50]}...': {e}\")\n",
    "        return -1 # Indicate failure\n",
    "    # --- !!! END OF HYPOTHETICAL BLOCK TO BE REPLACED !!! ---\n",
    "\n",
    "def evaluate_classifier(dataset_path: str):\n",
    "    \"\"\"Reads dataset, classifies text, and evaluates accuracy.\"\"\"\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    failed_classifications = 0\n",
    "\n",
    "    try:\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as file:\n",
    "            first_line = file.readline()\n",
    "            if not first_line:\n",
    "                print(f\"Error: Dataset file '{dataset_path}' is empty.\")\n",
    "                sys.exit(1)\n",
    "            file.seek(0)\n",
    "            \n",
    "            reader = csv.DictReader(file)\n",
    "            if 'text' not in reader.fieldnames or 'label' not in reader.fieldnames:\n",
    "                 print(f\"Error: Dataset file '{dataset_path}' must contain 'text' and 'label' columns.\")\n",
    "                 sys.exit(1)\n",
    "\n",
    "            print(f\"Starting evaluation using dataset: {dataset_path}\")\n",
    "            for i, row in enumerate(reader):\n",
    "                total_samples += 1\n",
    "                text = row.get('text', '')\n",
    "                label_str = row.get('label', '')\n",
    "\n",
    "                if not text:\n",
    "                    print(f\"Warning: Skipping row {i+1} due to empty 'text'.\")\n",
    "                    failed_classifications += 1\n",
    "                    continue\n",
    "                    \n",
    "                try:\n",
    "                    true_label = int(label_str)\n",
    "                    if true_label not in [0, 1]:\n",
    "                         print(f\"Warning: Skipping row {i+1} due to invalid label value: {label_str}\")\n",
    "                         failed_classifications += 1\n",
    "                         continue\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Skipping row {i+1} due to non-integer label: '{label_str}'\")\n",
    "                    failed_classifications += 1\n",
    "                    continue\n",
    "\n",
    "                predicted_label = classify_with_gemini(text)\n",
    "\n",
    "                if predicted_label == -1:\n",
    "                    failed_classifications += 1\n",
    "                    continue \n",
    "\n",
    "                if predicted_label == true_label:\n",
    "                    correct_predictions += 1\n",
    "                \n",
    "                if total_samples % 50 == 0:\n",
    "                    print(f\"Processed {total_samples} rows...\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: Dataset file not found at '{dataset_path}'\")\n",
    "        sys.exit(1)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during evaluation: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    valid_predictions = total_samples - failed_classifications\n",
    "    print(\"\n",
    "--- Evaluation Results ---\")\n",
    "    print(f\"Total samples processed: {total_samples}\")\n",
    "    print(f\"Samples skipped/failed: {failed_classifications}\")\n",
    "    \n",
    "    if valid_predictions > 0:\n",
    "        accuracy = (correct_predictions / valid_predictions) * 100\n",
    "        print(f\"Successfully classified: {valid_predictions}\")\n",
    "        print(f\"Correct predictions: {correct_predictions}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "    else:\n",
    "        print(\"No samples were successfully classified to calculate accuracy.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    dataset_file = 'dataset.csv' \n",
    "    evaluate_classifier(dataset_file)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
